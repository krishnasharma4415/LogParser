{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k:\\Computer Science\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import RobertaTokenizer, RobertaModel, AdamW, get_linear_schedule_with_warmup\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "import logging\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm, trange\n",
    "import re\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22000 entries, 0 to 21999\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   timestamp      22000 non-null  object\n",
      " 1   LineId         22000 non-null  int64 \n",
      " 2   Component      22000 non-null  object\n",
      " 3   Content        22000 non-null  object\n",
      " 4   EventId        22000 non-null  object\n",
      " 5   EventTemplate  22000 non-null  object\n",
      " 6   log            22000 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "df = df.head(22000)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Column: timestamp\n",
      "INFO:__main__:Unique values: 13167\n",
      "INFO:__main__:Min: 0, Max: 13166\n",
      "INFO:__main__:---\n",
      "INFO:__main__:Column: LineId\n",
      "INFO:__main__:Unique values: 2000\n",
      "INFO:__main__:Min: 0, Max: 1999\n",
      "INFO:__main__:---\n",
      "INFO:__main__:Column: Component\n",
      "INFO:__main__:Unique values: 299\n",
      "INFO:__main__:Min: 0, Max: 298\n",
      "INFO:__main__:---\n",
      "INFO:__main__:Column: Content\n",
      "INFO:__main__:Unique values: 11001\n",
      "INFO:__main__:Min: 0, Max: 11000\n",
      "INFO:__main__:---\n",
      "INFO:__main__:Column: EventId\n",
      "INFO:__main__:Unique values: 341\n",
      "INFO:__main__:Min: 0, Max: 340\n",
      "INFO:__main__:---\n",
      "INFO:__main__:Column: EventTemplate\n",
      "INFO:__main__:Unique values: 944\n",
      "INFO:__main__:Min: 0, Max: 943\n",
      "INFO:__main__:---\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def preprocess_df(df):\n",
    "    features = ['log']\n",
    "    target_labels = ['timestamp', 'LineId', 'Component', 'Content', 'EventId', 'EventTemplate']\n",
    "    label_encoders = {}\n",
    "    label_columns = []\n",
    "\n",
    "    df['log'] = df['log'].apply(preprocess_text)\n",
    "\n",
    "    for col in target_labels:\n",
    "        le = LabelEncoder()\n",
    "        df[col + '_encoded'] = le.fit_transform(df[col])\n",
    "        label_encoders[col] = le\n",
    "        label_columns.append(col + '_encoded')\n",
    "\n",
    "        logger.info(f\"Column: {col}\")\n",
    "        logger.info(f\"Unique values: {len(np.unique(df[col + '_encoded']))}\")\n",
    "        logger.info(f\"Min: {df[col + '_encoded'].min()}, Max: {df[col + '_encoded'].max()}\")\n",
    "        logger.info(\"---\")\n",
    "\n",
    "    return df, label_columns, label_encoders\n",
    "\n",
    "df, label_columns, label_encoders = preprocess_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogDataset(Dataset):\n",
    "    def __init__(self, logs, labels, tokenizer, max_len):\n",
    "        self.logs = logs\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.num_labels = [len(np.unique(labels[:, i])) for i in range(labels.shape[1])]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.logs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        log = str(self.logs[item])\n",
    "        labels = self.labels[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            log,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'log_text': log,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(labels, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique label values: [    0     1     2 ... 13164 13165 13166]\n",
      "Max label value: 13166\n",
      "Min label value: 0\n"
     ]
    }
   ],
   "source": [
    "class MultiTaskRobertaModel(nn.Module):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super(MultiTaskRobertaModel, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifiers = nn.ModuleList([nn.Linear(self.roberta.config.hidden_size, num_label) for num_label in num_labels])\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs[0]\n",
    "        pooled_output = self.dropout(sequence_output[:, 0])\n",
    "\n",
    "        logits = [classifier(pooled_output) for classifier in self.classifiers]\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            losses = [loss_fct(logit, label) for logit, label in zip(logits, labels.T)]\n",
    "            loss = sum(losses)\n",
    "            return loss, logits\n",
    "        return logits\n",
    "\n",
    "print(\"Unique label values:\", np.unique(df[label_columns].values))\n",
    "print(\"Max label value:\", np.max(df[label_columns].values))\n",
    "print(\"Min label value:\", np.min(df[label_columns].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels for each task: [13167, 2000, 299, 11001, 341, 944]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k:\\Computer Science\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\krish\\.cache\\huggingface\\hub\\models--roberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "num_labels = [len(np.unique(df[col])) for col in label_columns]\n",
    "print(\"Number of labels for each task:\", num_labels)\n",
    "model = MultiTaskRobertaModel('roberta-base', num_labels)\n",
    "\n",
    "logs = df['log'].values.tolist()\n",
    "labels = df[label_columns].values\n",
    "\n",
    "dataset = LogDataset(logs, labels, tokenizer, max_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 16\n",
    "learning_rate = 2e-5\n",
    "num_warmup_steps = 0\n",
    "num_folds = 5\n",
    "\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "k:\\Computer Science\\.venv\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1/10:   2%|▏         | 19/1100 [01:05<1:01:48,  3.43s/it, loss=42.1495]\n",
      "Epochs:   0%|          | 0/10 [01:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 33\u001b[0m\n\u001b[0;32m     28\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m     31\u001b[0m }\n\u001b[0;32m     32\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 33\u001b[0m loss, logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     35\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mk:\\Computer Science\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mk:\\Computer Science\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m, in \u001b[0;36mMultiTaskRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, labels)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m----> 9\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     11\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(sequence_output[:, \u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mk:\\Computer Science\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mk:\\Computer Science\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mk:\\Computer Science\\.venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:976\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m    974\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 976\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    989\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mk:\\Computer Science\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mk:\\Computer Science\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mk:\\Computer Science\\.venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:631\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    620\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    621\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    622\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    628\u001b[0m         output_attentions,\n\u001b[0;32m    629\u001b[0m     )\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 631\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    641\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mk:\\Computer Science\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mk:\\Computer Science\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mk:\\Computer Science\\.venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:562\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    559\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    560\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 562\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    565\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    567\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mk:\\Computer Science\\.venv\\Lib\\site-packages\\transformers\\pytorch_utils.py:248\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mk:\\Computer Science\\.venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:575\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m    574\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 575\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mk:\\Computer Science\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mk:\\Computer Science\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mk:\\Computer Science\\.venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:486\u001b[0m, in \u001b[0;36mRobertaOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 486\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    487\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    488\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32mk:\\Computer Science\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mk:\\Computer Science\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mk:\\Computer Science\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "    print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    val_subsampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_subsampler)\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_subsampler)\n",
    "    \n",
    "    model = MultiTaskRobertaModel('roberta-base', num_labels).to(device)\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, correct_bias=False)\n",
    "    total_steps = len(train_loader) * num_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=total_steps)\n",
    "\n",
    "    for epoch in trange(num_epochs, desc=\"Epochs\"):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        all_preds = [[] for _ in range(len(label_columns))]\n",
    "        all_labels = [[] for _ in range(len(label_columns))]\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        for batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            inputs = {\n",
    "                'input_ids': batch['input_ids'].to(device),\n",
    "                'attention_mask': batch['attention_mask'].to(device),\n",
    "            }\n",
    "            labels = batch['labels'].to(device)\n",
    "            loss, logits = model(**inputs, labels=labels)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            for i, logit in enumerate(logits):\n",
    "                preds = logit.argmax(dim=-1).detach().cpu().numpy()\n",
    "                all_preds[i].extend(preds)\n",
    "                all_labels[i].extend(labels[:, i].cpu().numpy())\n",
    "            \n",
    "            progress_bar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "            \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds = [[] for _ in range(len(label_columns))]\n",
    "        val_labels = [[] for _ in range(len(label_columns))]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = {\n",
    "                    'input_ids': batch['input_ids'].to(device),\n",
    "                    'attention_mask': batch['attention_mask'].to(device),\n",
    "                }\n",
    "                labels = batch['labels'].to(device)\n",
    "                loss, logits = model(**inputs, labels=labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                for i, logit in enumerate(logits):\n",
    "                    preds = logit.argmax(dim=-1).detach().cpu().numpy()\n",
    "                    val_preds[i].extend(preds)\n",
    "                    val_labels[i].extend(labels[:, i].cpu().numpy())\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        logger.info(f\"Fold {fold + 1}, Epoch {epoch + 1}/{num_epochs}\")\n",
    "        logger.info(f\"Training Loss: {avg_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        for i, (preds, labels) in enumerate(zip(val_preds, val_labels)):\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "            accuracy = accuracy_score(labels, preds)\n",
    "            \n",
    "            logger.info(f\"Task {i+1} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "            \n",
    "            cm = confusion_matrix(labels, preds)\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(cm, annot=True, fmt='d')\n",
    "            plt.title(f'Confusion Matrix for Task {i+1}')\n",
    "            plt.ylabel('Actual')\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.savefig(f'confusion_matrix_fold{fold+1}_task{i+1}_epoch{epoch+1}.png')\n",
    "            plt.close()\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model = model.state_dict()\n",
    "            torch.save(best_model, './best_model.pth')\n",
    "            print(f\"New best model saved with validation loss: {best_val_loss}\")\n",
    "\n",
    "\n",
    "print(f\"Best model had a validation loss of {best_val_loss}\")\n",
    "\n",
    "model.load_state_dict(torch.load('./best_model.pth'))\n",
    "\n",
    "tokenizer.save_pretrained('./tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15292\\3547099798.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth', map_location=device))\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = MultiTaskRobertaModel('roberta-base', [len(le.classes_) for le in label_encoders.values()])\n",
    "model.load_state_dict(torch.load('best_model.pth', map_location=device))\n",
    "model.eval()\n",
    "tokenizer = RobertaTokenizer.from_pretrained('./tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Log:\n",
      "  5,2016-09-28,04:30:31,Info,CBS,Ending TrustedInstaller initialization.,E17,Ending TrustedInstaller initialization.\n",
      "\n",
      "Predictions:\n",
      "  LineId:\n",
      "    Value: 1852\n",
      "    Confidence: 0.0313\n",
      "\n",
      "  timestamp:\n",
      "    Value: 2016-09-29 00:00:46\n",
      "    Confidence: 0.0021\n",
      "\n",
      "  Component:\n",
      "    Value: CBS\n",
      "    Confidence: 0.2770\n",
      "\n",
      "  Content:\n",
      "    Value: Interrupting SendWorker\n",
      "    Confidence: 0.0122\n",
      "\n",
      "  EventId:\n",
      "    Value: E7\n",
      "    Confidence: 0.1519\n",
      "\n",
      "  EventTemplate:\n",
      "    Value: Interrupting SendWorker\n",
      "    Confidence: 0.0196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def predict_log_details(log_text, model, tokenizer, label_encoders, device):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(preprocess_text(log_text), return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs)\n",
    "    \n",
    "    predictions = [logit.cpu().numpy().argmax(axis=1)[0] for logit in logits]\n",
    "    confidence_scores = [torch.softmax(logit, dim=1).max().item() for logit in logits]\n",
    "    \n",
    "    interpreted_predictions = OrderedDict([\n",
    "        ('LineId', label_encoders['LineId'].inverse_transform([predictions[1]])[0]),\n",
    "        ('timestamp', label_encoders['timestamp'].inverse_transform([predictions[0]])[0]),\n",
    "        ('Component', label_encoders['Component'].inverse_transform([predictions[2]])[0]),\n",
    "        ('Content', label_encoders['Content'].inverse_transform([predictions[3]])[0]),\n",
    "        ('EventId', label_encoders['EventId'].inverse_transform([predictions[4]])[0]),\n",
    "        ('EventTemplate', label_encoders['EventTemplate'].inverse_transform([predictions[5]])[0])\n",
    "    ])\n",
    "    \n",
    "    result = OrderedDict()\n",
    "    result['input_log'] = log_text\n",
    "    result['predictions'] = OrderedDict()\n",
    "    \n",
    "    for i, (key, value) in enumerate(interpreted_predictions.items()):\n",
    "        result['predictions'][key] = {\n",
    "            'value': value,\n",
    "            'confidence': f\"{confidence_scores[i]:.4f}\"\n",
    "        }\n",
    "    \n",
    "    return result\n",
    "\n",
    "new_log = \"5,2016-09-28,04:30:31,Info,CBS,Ending TrustedInstaller initialization.,E17,Ending TrustedInstaller initialization.\"\n",
    "predicted_details = predict_log_details(new_log, model, tokenizer, label_encoders, device)\n",
    "\n",
    "def print_predictions(predictions):\n",
    "    print(\"Input Log:\")\n",
    "    print(f\"  {predictions['input_log']}\")\n",
    "    print(\"\\nPredictions:\")\n",
    "    for key, value in predictions['predictions'].items():\n",
    "        print(f\"  {key}:\")\n",
    "        print(f\"    Value: {value['value']}\")\n",
    "        print(f\"    Confidence: {value['confidence']}\")\n",
    "        print()\n",
    "\n",
    "print_predictions(predicted_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict_log_details(log_texts, model, tokenizer, label_encoders, device, batch_size=32):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    \n",
    "    for i in range(0, len(log_texts), batch_size):\n",
    "        batch_texts = log_texts[i:i+batch_size]\n",
    "        batch_texts = [preprocess_text(text) for text in batch_texts]\n",
    "        inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs)\n",
    "        \n",
    "        batch_predictions = [logit.cpu().numpy().argmax(axis=1) for logit in logits]\n",
    "        confidence_scores = [torch.softmax(logit, dim=1).max(dim=1)[0].cpu().numpy() for logit in logits]\n",
    "        \n",
    "        for j, original_text in enumerate(log_texts[i:i+batch_size]):\n",
    "            predictions = [pred[j] for pred in batch_predictions]\n",
    "            scores = [score[j] for score in confidence_scores]\n",
    "            \n",
    "            result = OrderedDict()\n",
    "            result['input_log'] = original_text\n",
    "            result['predictions'] = OrderedDict()\n",
    "            \n",
    "            for k, (key, le) in enumerate(label_encoders.items()):\n",
    "                result['predictions'][key] = {\n",
    "                    'value': le.inverse_transform([predictions[k]])[0],\n",
    "                    'confidence': f\"{scores[k]:.4f}\"\n",
    "                }\n",
    "            \n",
    "            all_predictions.append(result)\n",
    "    \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: SyntaxWarning: invalid escape sequence '\\W'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\W'\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15292\\4015372975.py:14: SyntaxWarning: invalid escape sequence '\\W'\n",
      "  \"2016-09-28 04:30:31, Info                  CBS    SQM: Failed to start upload with file pattern: C:\\Windows\\servicing\\sqm\\*_std.sqm, flags: 0x2 [HRESULT = 0x80004005 - E_FAIL]\",\n"
     ]
    }
   ],
   "source": [
    "batch_logs = [\"03-17 16:13:38.811  1702  2395 D WindowManager: printFreezingDisplayLogsopening app wtoken = AppWindowToken{9f4ef63 token=Token{a64f992 ActivityRecord{de9231d u0 com.tencent.qt.qtl/.activity.info.NewsDetailXmlActivity t761}}}, allDrawn= false, startingDisplayed =  false, startingMoved =  false, isRelaunching =  false\",\n",
    "              \"1117838976 2005.06.03 R02-M1-N0-C:J12-U11 2005-06-03-15.49.36.156884 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\",\n",
    "              \"2015-10-18 18:01:50,572 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventType for class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler\",\n",
    "              \"081109 204842 663 INFO dfs.DataNode$DataXceiver: Receiving block blk_1724757848743533110 src: /10.251.111.130:49851 dest: /10.251.111.130:50010\",\n",
    "              \"20171223-22:15:29:950|Step_SPUtils|30002312|setTodayTotalDetailSteps=1514038440000##7008##548365##8661##12456##27174269\",\n",
    "              \"360778 node-130 unix.hw state_change.unavailable 1141108031 1 Component State Change: Component \\042alt0\\042 is in the unavailable state (HWID=2478)\",\n",
    "              \"Jun 15 02:04:59 combo sshd(pam_unix)[20892]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=220-135-151-1.hinet-ip.hinet.net  user=root\",\n",
    "              \"Jul  1 09:04:37 authorMacBook-Pro symptomsd[215]: __73-[NetworkAnalyticsEngine observeValueForKeyPath:ofObject:change:context:]_block_invoke unexpected switch value 2\",\n",
    "              \"Dec 10 07:08:28 LabSZ sshd[24208]: reverse mapping checking getaddrinfo for ns.marryaldkfaczcz.com [173.234.31.186] failed - POSSIBLE BREAK-IN ATTEMPT!\",\n",
    "              \"nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:00:04.500 2931 INFO nova.compute.manager [req-3ea4052c-895d-4b64-9e2d-04d64c4d94ab - - - - -] [instance: b9000564-fe1a-409b-b8cc-1e88b294cd1d] VM Started (Lifecycle Event)\",\n",
    "              \"[10.30 16:49:08] chrome.exe - proxy.cse.cuhk.edu.hk:5070 close, 1190 bytes (1.16 KB) sent, 1671 bytes (1.63 KB) received, lifetime 00:02\",\n",
    "              \"17/06/09 20:10:41 INFO storage.DiskBlockManager: Created local directory at /opt/hdfs/nodemanager/usercache/curi/appcache/application_1485248649253_0147/blockmgr-70293f72-844a-4b39-9ad6-fb0ad7e364e4\",\n",
    "              \"1131566461 2005.11.09 dn700 Nov 9 12:01:01 dn700/dn700 crond(pam_unix)[2912]: session opened for user root by (uid=0)\",\n",
    "              \"2016-09-28 04:30:31, Info                  CBS    SQM: Failed to start upload with file pattern: C:\\Windows\\servicing\\sqm\\*_std.sqm, flags: 0x2 [HRESULT = 0x80004005 - E_FAIL]\",\n",
    "              \"2015-07-29 19:13:27,721 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 1, error = \",\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_predictions = batch_predict_log_details(batch_logs, model, tokenizer, label_encoders, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log 1:\n",
      "  Input: 03-17 16:13:38.811  1702  2395 D WindowManager: printFreezingDisplayLogsopening app wtoken = AppWindowToken{9f4ef63 token=Token{a64f992 ActivityRecord{de9231d u0 com.tencent.qt.qtl/.activity.info.NewsDetailXmlActivity t761}}}, allDrawn= false, startingDisplayed =  false, startingMoved =  false, isRelaunching =  false\n",
      "  Predictions:\n",
      "    timestamp:\n",
      "      Value: 2017-05-16 00:01:17.920\n",
      "      Confidence: 0.0005\n",
      "    LineId:\n",
      "      Value: 1745\n",
      "      Confidence: 0.0026\n",
      "    Component:\n",
      "      Value: symptomsd\n",
      "      Confidence: 0.0694\n",
      "    Content:\n",
      "      Value: -[NetworkAnalyticsEngine _writeJournalRecord:fromCellFingerprint:key:atLOI:ofKind:lqm:isFaulty:] Hashing of the primary key failed. Dropping the journal record.\n",
      "      Confidence: 0.0008\n",
      "    EventId:\n",
      "      Value: E7\n",
      "      Confidence: 0.0432\n",
      "    EventTemplate:\n",
      "      Value: -[UABestAppSuggestionManager notifyBestAppChanged:type:options:bundleIdentifier:activityType:dynamicIdentifier:when:confidence:deviceName:deviceIdentifier:deviceType:] (null) UASuggestedActionType=<*> (null)/(null) opts=(null) when=<*>\n",
      "      Confidence: 0.0192\n",
      "\n",
      "Log 2:\n",
      "  Input: 1117838976 2005.06.03 R02-M1-N0-C:J12-U11 2005-06-03-15.49.36.156884 R02-M1-N0-C:J12-U11 RAS KERNEL INFO instruction cache parity error corrected\n",
      "  Predictions:\n",
      "    timestamp:\n",
      "      Value: 1131566461 2005.11.09 Nov 9 12:01:01\n",
      "      Confidence: 0.0129\n",
      "    LineId:\n",
      "      Value: 1909\n",
      "      Confidence: 0.0022\n",
      "    Component:\n",
      "      Value: switch_module\n",
      "      Confidence: 0.1463\n",
      "    Content:\n",
      "      Value: (root) CMD (run-parts /etc/cron.hourly)\n",
      "      Confidence: 0.0055\n",
      "    EventId:\n",
      "      Value: E13\n",
      "      Confidence: 0.1141\n",
      "    EventTemplate:\n",
      "      Value: reverse mapping checking getaddrinfo for <*> [<*>] failed - POSSIBLE BREAK-IN ATTEMPT!\n",
      "      Confidence: 0.0312\n",
      "\n",
      "Log 3:\n",
      "  Input: 2015-10-18 18:01:50,572 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventType for class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler\n",
      "  Predictions:\n",
      "    timestamp:\n",
      "      Value: Jul 2 21:17:07\n",
      "      Confidence: 0.0005\n",
      "    LineId:\n",
      "      Value: 1233\n",
      "      Confidence: 0.0027\n",
      "    Component:\n",
      "      Value: 2 cport:-1)::PrepRequestProcessor\n",
      "      Confidence: 0.0310\n",
      "    Content:\n",
      "      Value: -[NetworkAnalyticsEngine _writeJournalRecord:fromCellFingerprint:key:atLOI:ofKind:lqm:isFaulty:] Hashing of the primary key failed. Dropping the journal record.\n",
      "      Confidence: 0.0008\n",
      "    EventId:\n",
      "      Value: E7\n",
      "      Confidence: 0.0390\n",
      "    EventTemplate:\n",
      "      Value: Established session <*> with negotiated timeout <*> for client /<*>:<*>\n",
      "      Confidence: 0.0191\n",
      "\n",
      "Log 4:\n",
      "  Input: 081109 204842 663 INFO dfs.DataNode$DataXceiver: Receiving block blk_1724757848743533110 src: /10.251.111.130:49851 dest: /10.251.111.130:50010\n",
      "  Predictions:\n",
      "    timestamp:\n",
      "      Value: 81110 105252\n",
      "      Confidence: 0.0010\n",
      "    LineId:\n",
      "      Value: 730\n",
      "      Confidence: 0.0026\n",
      "    Component:\n",
      "      Value: dfs.DataNode$DataXceiver\n",
      "      Confidence: 0.9978\n",
      "    Content:\n",
      "      Value: Receiving block blk_4742178675580222210 src: /10.251.42.9:60232 dest: /10.251.42.9:50010\n",
      "      Confidence: 0.0014\n",
      "    EventId:\n",
      "      Value: E13\n",
      "      Confidence: 0.9950\n",
      "    EventTemplate:\n",
      "      Value: Receiving block blk_<*> src: /<*>:<*> dest: /<*>:<*>\n",
      "      Confidence: 0.9980\n",
      "\n",
      "Log 5:\n",
      "  Input: 20171223-22:15:29:950|Step_SPUtils|30002312|setTodayTotalDetailSteps=1514038440000##7008##548365##8661##12456##27174269\n",
      "  Predictions:\n",
      "    timestamp:\n",
      "      Value: 20171223-23:17:40:996\n",
      "      Confidence: 0.0015\n",
      "    LineId:\n",
      "      Value: 948\n",
      "      Confidence: 0.0035\n",
      "    Component:\n",
      "      Value: Step_SPUtils\n",
      "      Confidence: 0.9978\n",
      "    Content:\n",
      "      Value: setTodayTotalDetailSteps=1514038680000##7139##548905##8661##16256##27396473\n",
      "      Confidence: 0.0012\n",
      "    EventId:\n",
      "      Value: E58\n",
      "      Confidence: 0.9936\n",
      "    EventTemplate:\n",
      "      Value: setTodayTotalDetailSteps=<*>\n",
      "      Confidence: 0.9967\n",
      "\n",
      "Log 6:\n",
      "  Input: 360778 node-130 unix.hw state_change.unavailable 1141108031 1 Component State Change: Component \"alt0\" is in the unavailable state (HWID=2478)\n",
      "  Predictions:\n",
      "    timestamp:\n",
      "      Value: 17/06/09 20:10:58\n",
      "      Confidence: 0.0010\n",
      "    LineId:\n",
      "      Value: 3\n",
      "      Confidence: 0.0025\n",
      "    Component:\n",
      "      Value: unix.hw\n",
      "      Confidence: 0.9323\n",
      "    Content:\n",
      "      Value: Cannot open channel to 2 at election address /10.10.34.12:3888\n",
      "      Confidence: 0.0031\n",
      "    EventId:\n",
      "      Value: E13\n",
      "      Confidence: 0.9038\n",
      "    EventTemplate:\n",
      "      Value: Component State Change: Component <*> is in the unavailable state (HWID=<*>)\n",
      "      Confidence: 0.6008\n",
      "\n",
      "Log 7:\n",
      "  Input: Jun 15 02:04:59 combo sshd(pam_unix)[20892]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=220-135-151-1.hinet-ip.hinet.net  user=root\n",
      "  Predictions:\n",
      "    timestamp:\n",
      "      Value: Jun 15 02:04:59\n",
      "      Confidence: 0.0181\n",
      "    LineId:\n",
      "      Value: 1181\n",
      "      Confidence: 0.0028\n",
      "    Component:\n",
      "      Value: sshd(pam_unix)\n",
      "      Confidence: 0.9972\n",
      "    Content:\n",
      "      Value: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=n219076184117.netvigator.com  user=root\n",
      "      Confidence: 0.1396\n",
      "    EventId:\n",
      "      Value: E18\n",
      "      Confidence: 0.9910\n",
      "    EventTemplate:\n",
      "      Value: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=<*>  user=root\n",
      "      Confidence: 0.9969\n",
      "\n",
      "Log 8:\n",
      "  Input: Jul  1 09:04:37 authorMacBook-Pro symptomsd[215]: __73-[NetworkAnalyticsEngine observeValueForKeyPath:ofObject:change:context:]_block_invoke unexpected switch value 2\n",
      "  Predictions:\n",
      "    timestamp:\n",
      "      Value: 2016-09-28 04:30:31\n",
      "      Confidence: 0.0027\n",
      "    LineId:\n",
      "      Value: 1442\n",
      "      Confidence: 0.0021\n",
      "    Component:\n",
      "      Value: symptomsd\n",
      "      Confidence: 0.7840\n",
      "    Content:\n",
      "      Value: __73-[NetworkAnalyticsEngine observeValueForKeyPath:ofObject:change:context:]_block_invoke unexpected switch value 2\n",
      "      Confidence: 0.6437\n",
      "    EventId:\n",
      "      Value: E50\n",
      "      Confidence: 0.9203\n",
      "    EventTemplate:\n",
      "      Value: __<*>-[NetworkAnalyticsEngine observeValueForKeyPath:ofObject:change:context:]_block_invoke unexpected switch value <*>\n",
      "      Confidence: 0.7227\n",
      "\n",
      "Log 9:\n",
      "  Input: Dec 10 07:08:28 LabSZ sshd[24208]: reverse mapping checking getaddrinfo for ns.marryaldkfaczcz.com [173.234.31.186] failed - POSSIBLE BREAK-IN ATTEMPT!\n",
      "  Predictions:\n",
      "    timestamp:\n",
      "      Value: Dec 10 09:18:40\n",
      "      Confidence: 0.0040\n",
      "    LineId:\n",
      "      Value: 704\n",
      "      Confidence: 0.0027\n",
      "    Component:\n",
      "      Value: LabSZ\n",
      "      Confidence: 0.9989\n",
      "    Content:\n",
      "      Value: reverse mapping checking getaddrinfo for customer-187-141-143-180-sta.uninet-ide.com.mx [187.141.143.180] failed - POSSIBLE BREAK-IN ATTEMPT!\n",
      "      Confidence: 0.8927\n",
      "    EventId:\n",
      "      Value: E27\n",
      "      Confidence: 0.9716\n",
      "    EventTemplate:\n",
      "      Value: reverse mapping checking getaddrinfo for <*> [<*>] failed - POSSIBLE BREAK-IN ATTEMPT!\n",
      "      Confidence: 0.9841\n",
      "\n",
      "Log 10:\n",
      "  Input: nova-compute.log.1.2017-05-16_13:55:31 2017-05-16 00:00:04.500 2931 INFO nova.compute.manager [req-3ea4052c-895d-4b64-9e2d-04d64c4d94ab - - - - -] [instance: b9000564-fe1a-409b-b8cc-1e88b294cd1d] VM Started (Lifecycle Event)\n",
      "  Predictions:\n",
      "    timestamp:\n",
      "      Value: 2017-05-16 00:02:55.757\n",
      "      Confidence: 0.0008\n",
      "    LineId:\n",
      "      Value: 1575\n",
      "      Confidence: 0.0025\n",
      "    Component:\n",
      "      Value: nova.compute.manager\n",
      "      Confidence: 0.9826\n",
      "    Content:\n",
      "      Value: [instance: 70c1714b-c11b-4c88-b300-239afe1f5ff8] VM Started (Lifecycle Event)\n",
      "      Confidence: 0.0014\n",
      "    EventId:\n",
      "      Value: E22\n",
      "      Confidence: 0.9385\n",
      "    EventTemplate:\n",
      "      Value: [instance: <*>] VM Started (Lifecycle Event)\n",
      "      Confidence: 0.9227\n",
      "\n",
      "Log 11:\n",
      "  Input: [10.30 16:49:08] chrome.exe - proxy.cse.cuhk.edu.hk:5070 close, 1190 bytes (1.16 KB) sent, 1671 bytes (1.63 KB) received, lifetime 00:02\n",
      "  Predictions:\n",
      "    timestamp:\n",
      "      Value: 17/06/09 20:10:48\n",
      "      Confidence: 0.0315\n",
      "    LineId:\n",
      "      Value: 1109\n",
      "      Confidence: 0.0027\n",
      "    Component:\n",
      "      Value: storage.MemoryStore\n",
      "      Confidence: 0.5835\n",
      "    Content:\n",
      "      Value: Authentication failed from 163.27.187.39 (163.27.187.39): Software caused connection abort\n",
      "      Confidence: 0.0022\n",
      "    EventId:\n",
      "      Value: E9\n",
      "      Confidence: 0.4581\n",
      "    EventTemplate:\n",
      "      Value: Block <*> stored as bytes in memory (estimated size <*>, free <*>)\n",
      "      Confidence: 0.3603\n",
      "\n",
      "Log 12:\n",
      "  Input: 17/06/09 20:10:41 INFO storage.DiskBlockManager: Created local directory at /opt/hdfs/nodemanager/usercache/curi/appcache/application_1485248649253_0147/blockmgr-70293f72-844a-4b39-9ad6-fb0ad7e364e4\n",
      "  Predictions:\n",
      "    timestamp:\n",
      "      Value: 2016-09-29 00:03:19\n",
      "      Confidence: 0.0007\n",
      "    LineId:\n",
      "      Value: 947\n",
      "      Confidence: 0.0029\n",
      "    Component:\n",
      "      Value: dfs.FSNamesystem\n",
      "      Confidence: 0.2973\n",
      "    Content:\n",
      "      Value: Interrupted while waiting for message on queue\n",
      "      Confidence: 0.0015\n",
      "    EventId:\n",
      "      Value: E7\n",
      "      Confidence: 0.7333\n",
      "    EventTemplate:\n",
      "      Value: BLOCK* NameSystem.allocateBlock: /<*>/part-<*>. blk_<*>\n",
      "      Confidence: 0.2610\n",
      "\n",
      "Log 13:\n",
      "  Input: 1131566461 2005.11.09 dn700 Nov 9 12:01:01 dn700/dn700 crond(pam_unix)[2912]: session opened for user root by (uid=0)\n",
      "  Predictions:\n",
      "    timestamp:\n",
      "      Value: 1131566461 2005.11.09 Nov 9 12:01:01\n",
      "      Confidence: 0.6191\n",
      "    LineId:\n",
      "      Value: 133\n",
      "      Confidence: 0.0035\n",
      "    Component:\n",
      "      Value: crond(pam_unix)\n",
      "      Confidence: 0.9560\n",
      "    Content:\n",
      "      Value: session opened for user root by (uid=0)\n",
      "      Confidence: 0.6719\n",
      "    EventId:\n",
      "      Value: E118\n",
      "      Confidence: 0.7675\n",
      "    EventTemplate:\n",
      "      Value: session opened for user root by (uid=0)\n",
      "      Confidence: 0.7828\n",
      "\n",
      "Log 14:\n",
      "  Input: 2016-09-28 04:30:31, Info                  CBS    SQM: Failed to start upload with file pattern: C:\\Windows\\servicing\\sqm\\*_std.sqm, flags: 0x2 [HRESULT = 0x80004005 - E_FAIL]\n",
      "  Predictions:\n",
      "    timestamp:\n",
      "      Value: 2016-09-28 04:30:31\n",
      "      Confidence: 0.6354\n",
      "    LineId:\n",
      "      Value: 1727\n",
      "      Confidence: 0.0023\n",
      "    Component:\n",
      "      Value: CBS\n",
      "      Confidence: 0.9836\n",
      "    Content:\n",
      "      Value: Expecting attribute name [HRESULT = 0x800f080d - CBS_E_MANIFEST_INVALID_ITEM]\n",
      "      Confidence: 0.0385\n",
      "    EventId:\n",
      "      Value: E39\n",
      "      Confidence: 0.0835\n",
      "    EventTemplate:\n",
      "      Value: Failed to get next element [HRESULT = <*> - CBS_E_MANIFEST_INVALID_ITEM]\n",
      "      Confidence: 0.0512\n",
      "\n",
      "Log 15:\n",
      "  Input: 2015-07-29 19:13:27,721 - WARN  [RecvWorker:188978561024:QuorumCnxManager$RecvWorker@762] - Connection broken for id 188978561024, my id = 1, error = \n",
      "  Predictions:\n",
      "    timestamp:\n",
      "      Value: 17/06/09 20:10:53\n",
      "      Confidence: 0.0021\n",
      "    LineId:\n",
      "      Value: 1890\n",
      "      Confidence: 0.0035\n",
      "    Component:\n",
      "      Value: 188978561024:QuorumCnxManager$RecvWorker\n",
      "      Confidence: 0.9777\n",
      "    Content:\n",
      "      Value: Connection broken for id 188978561024, my id = 1, error =\n",
      "      Confidence: 0.9718\n",
      "    EventId:\n",
      "      Value: E11\n",
      "      Confidence: 0.9963\n",
      "    EventTemplate:\n",
      "      Value: Connection broken for id <*>, my id = <*>, error =\n",
      "      Confidence: 0.9955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_batch_predictions(predictions):\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        print(f\"Log {i + 1}:\")\n",
    "        print(f\"  Input: {prediction['input_log']}\")\n",
    "        print(\"  Predictions:\")\n",
    "        for key, value in prediction['predictions'].items():\n",
    "            print(f\"    {key}:\")\n",
    "            print(f\"      Value: {value['value']}\")\n",
    "            print(f\"      Confidence: {value['confidence']}\")\n",
    "        print()\n",
    "\n",
    "print_batch_predictions(batch_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
